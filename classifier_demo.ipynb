{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('input1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>page_no</th>\n",
       "      <th>features</th>\n",
       "      <th>tech_debt</th>\n",
       "      <th>security</th>\n",
       "      <th>arch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1122</td>\n",
       "      <td>8</td>\n",
       "      <td>Network Protocol: HTTP</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1122</td>\n",
       "      <td>8</td>\n",
       "      <td>OS: Windows 8 / 8.1 / 10 (64-bit OS required)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1122</td>\n",
       "      <td>8</td>\n",
       "      <td>OS: Windows 7 / 8 / 8.1 / 10 (64-bit OS required)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1122</td>\n",
       "      <td>8</td>\n",
       "      <td>Memory: 4 GB RAM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1122</td>\n",
       "      <td>9</td>\n",
       "      <td>Graphics: NVIDIA GeForce GTX 750Ti(2 GB)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document_id  page_no                                           features  \\\n",
       "0         1122        8                             Network Protocol: HTTP   \n",
       "1         1122        8      OS: Windows 8 / 8.1 / 10 (64-bit OS required)   \n",
       "2         1122        8  OS: Windows 7 / 8 / 8.1 / 10 (64-bit OS required)   \n",
       "3         1122        8                                   Memory: 4 GB RAM   \n",
       "4         1122        9           Graphics: NVIDIA GeForce GTX 750Ti(2 GB)   \n",
       "\n",
       "   tech_debt  security  arch  \n",
       "0          0         1     0  \n",
       "1          0         0     0  \n",
       "2          1         0     0  \n",
       "3          0         0     1  \n",
       "4          0         0     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show a few examples and structure of data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data here was obtained from Steam for specific game requirements. This is meant to mimic the nature of specifications data extracted from design documents. Two main (reasonable) assumption:\n",
    "- Certain products/specifications will have multiple instances across our dataset\n",
    "- A certain category will have various specifications corresponding to it. Risk categories chosen: Technology debt, Security, Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "# Function to to do some basic cleanup\n",
    "def clean_all(text):\n",
    "    text = text.lower()  # make lowercase\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')  # remove emoji characters\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)  # remove punctuation\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New column for the cleaned text\n",
    "df['cleaned_feat'] = df['features'].apply(clean_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>page_no</th>\n",
       "      <th>features</th>\n",
       "      <th>tech_debt</th>\n",
       "      <th>security</th>\n",
       "      <th>arch</th>\n",
       "      <th>cleaned_feat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1122</td>\n",
       "      <td>8</td>\n",
       "      <td>Network Protocol: HTTP</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>network protocol  http</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1122</td>\n",
       "      <td>8</td>\n",
       "      <td>OS: Windows 8 / 8.1 / 10 (64-bit OS required)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>os  windows 8   8 1   10  64 bit os required</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1122</td>\n",
       "      <td>8</td>\n",
       "      <td>OS: Windows 7 / 8 / 8.1 / 10 (64-bit OS required)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>os  windows 7   8   8 1   10  64 bit os required</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1122</td>\n",
       "      <td>8</td>\n",
       "      <td>Memory: 4 GB RAM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>memory  4 gb ram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1122</td>\n",
       "      <td>9</td>\n",
       "      <td>Graphics: NVIDIA GeForce GTX 750Ti(2 GB)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>graphics  nvidia geforce gtx 750ti 2 gb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document_id  page_no                                           features  \\\n",
       "0         1122        8                             Network Protocol: HTTP   \n",
       "1         1122        8      OS: Windows 8 / 8.1 / 10 (64-bit OS required)   \n",
       "2         1122        8  OS: Windows 7 / 8 / 8.1 / 10 (64-bit OS required)   \n",
       "3         1122        8                                   Memory: 4 GB RAM   \n",
       "4         1122        9           Graphics: NVIDIA GeForce GTX 750Ti(2 GB)   \n",
       "\n",
       "   tech_debt  security  arch  \\\n",
       "0          0         1     0   \n",
       "1          0         0     0   \n",
       "2          1         0     0   \n",
       "3          0         0     1   \n",
       "4          0         0     0   \n",
       "\n",
       "                                        cleaned_feat  \n",
       "0                             network protocol  http  \n",
       "1      os  windows 8   8 1   10  64 bit os required   \n",
       "2  os  windows 7   8   8 1   10  64 bit os required   \n",
       "3                                   memory  4 gb ram  \n",
       "4           graphics  nvidia geforce gtx 750ti 2 gb   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign words to vectors here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Due to the small dataset, we opted to created word vectors from a pre-trained word2vec model i.e. Glove. Note that given a reasonable dataset size, we can create a new word2vec model from scratch, which might lead to better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Glove model, publicly available\n",
    "file = open(\"glove.6B.300d.txt\", encoding=\"utf8\")\n",
    "\n",
    "# Save in dictionary\n",
    "word_vecs = {}\n",
    "for line in file:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:], \"float32\")\n",
    "    word_vecs[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign every feature in the dataeet to set of vectors\n",
    "# Might be a bit complicated here, essentially just incorporates words not exisiting in the pre-trained model as well\n",
    "feature_vecs = []\n",
    "for feature in df.cleaned_feat:\n",
    "    lst = feature.split()\n",
    "    num_words = len(lst)\n",
    "    feature_vec = np.zeros((1, 300))\n",
    "    for word_n in range(num_words):\n",
    "        word = lst[word_n]\n",
    "        if word in word_vecs:\n",
    "            x = word_vecs[word]\n",
    "            x = np.expand_dims(np.array(x), axis=-1)\n",
    "            feature_vec = np.concatenate((feature_vec, x.T))\n",
    "        else:\n",
    "            word_splitted = [char for char in word]\n",
    "            for word2 in word_splitted:\n",
    "                x = word_vecs[word2]\n",
    "                x = np.expand_dims(np.array(x), axis=-1)\n",
    "                feature_vec = np.concatenate((feature_vec, x.T))\n",
    "    feature_vec = feature_vec[1:, :]\n",
    "    feature_vecs.append(feature_vec)\n",
    "feature_vecs = np.array(feature_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress all the features to consistent vectors for training\n",
    "num_features = df.shape[0]\n",
    "num_categories = 3\n",
    "words_dim = 300\n",
    "feature_vecs_train = np.zeros((num_features, num_categories, words_dim))\n",
    "\n",
    "# Use singular value decomposition to get the three strongest features (orthogonal basis vectors) from all feature vectors\n",
    "for vec_n in range(len(feature_vecs)):\n",
    "    vec = feature_vecs[vec_n]\n",
    "    u, s, vh = np.linalg.svd(vec, full_matrices=True)\n",
    "    vec_reduced = vh[0:3, :]\n",
    "    feature_vecs_train[vec_n, :, :] = vec_reduced\n",
    "feature_vecs_train = np.reshape(feature_vecs_train, newshape=(df.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign all values to in training vectors between 0 and 1\n",
    "def scale_array(dat, out_range=(0, 1)):\n",
    "    domain = [np.min(dat, axis=0), np.max(dat, axis=0)]\n",
    "\n",
    "    def interp(x):\n",
    "        return out_range[0] * (1.0 - x) + out_range[1] * x\n",
    "\n",
    "    def uninterp(x):\n",
    "        b = 0\n",
    "        if (domain[1] - domain[0]) != 0:\n",
    "            b = domain[1] - domain[0]\n",
    "        else:\n",
    "            b =  1.0 / domain[1]\n",
    "        return (x - domain[0]) / b\n",
    "        \n",
    "    return interp(uninterp(dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(feature_vecs_train.shape[0]):\n",
    "    feature_vecs_train[i] = scale_array(feature_vecs_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple 3-layer Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple NN chosen. Mostly to investigate underlying relationships in the network and checking if it overfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels for all features first \n",
    "train_labels = np.zeros((num_features, num_categories))\n",
    "for i in range(num_features):\n",
    "    label = [df.tech_debt[i], df.security[i], df.arch[i]]\n",
    "    train_labels[i] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(200, input_dim=900, kernel_initializer='normal', activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(100, kernel_initializer='normal', activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(num_categories, kernel_initializer='normal', activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=tensorflow.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "# Implement dropout for proper training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49 samples\n",
      "Epoch 1/20\n",
      "49/49 [==============================] - 0s 753us/sample - loss: 0.1745 - accuracy: 0.7755\n",
      "Epoch 2/20\n",
      "49/49 [==============================] - 0s 651us/sample - loss: 0.0823 - accuracy: 0.7143\n",
      "Epoch 3/20\n",
      "49/49 [==============================] - 0s 753us/sample - loss: 0.0717 - accuracy: 0.7347\n",
      "Epoch 4/20\n",
      "49/49 [==============================] - 0s 672us/sample - loss: 0.0799 - accuracy: 0.7347\n",
      "Epoch 5/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 1.00 - 0s 692us/sample - loss: 0.0705 - accuracy: 0.7347\n",
      "Epoch 6/20\n",
      "49/49 [==============================] - 0s 733us/sample - loss: 0.0881 - accuracy: 0.7143\n",
      "Epoch 7/20\n",
      "49/49 [==============================] - 0s 692us/sample - loss: 0.0698 - accuracy: 0.7347\n",
      "Epoch 8/20\n",
      "49/49 [==============================] - 0s 672us/sample - loss: 0.0734 - accuracy: 0.7347\n",
      "Epoch 9/20\n",
      "49/49 [==============================] - 0s 651us/sample - loss: 0.0799 - accuracy: 0.7347\n",
      "Epoch 10/20\n",
      "49/49 [==============================] - 0s 631us/sample - loss: 0.0951 - accuracy: 0.6735\n",
      "Epoch 11/20\n",
      "49/49 [==============================] - 0s 651us/sample - loss: 0.1886 - accuracy: 0.5918\n",
      "Epoch 12/20\n",
      "49/49 [==============================] - 0s 651us/sample - loss: 0.0794 - accuracy: 0.6939\n",
      "Epoch 13/20\n",
      "49/49 [==============================] - 0s 692us/sample - loss: 0.0766 - accuracy: 0.7347\n",
      "Epoch 14/20\n",
      "49/49 [==============================] - 0s 631us/sample - loss: 0.0791 - accuracy: 0.7347\n",
      "Epoch 15/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 1.00 - 0s 611us/sample - loss: 0.1016 - accuracy: 0.7143\n",
      "Epoch 16/20\n",
      "49/49 [==============================] - 0s 611us/sample - loss: 0.0718 - accuracy: 0.7347\n",
      "Epoch 17/20\n",
      "49/49 [==============================] - 0s 651us/sample - loss: 0.0693 - accuracy: 0.7347\n",
      "Epoch 18/20\n",
      "49/49 [==============================] - 0s 651us/sample - loss: 0.0891 - accuracy: 0.7143\n",
      "Epoch 19/20\n",
      "49/49 [==============================] - 0s 631us/sample - loss: 0.2893 - accuracy: 0.5918\n",
      "Epoch 20/20\n",
      "49/49 [==============================] - 0s 631us/sample - loss: 0.1203 - accuracy: 0.7347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x251255e5cc0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(feature_vecs_train, train_labels, epochs=20, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss converging, seems to be overfitting. Consistent with assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Storage: 5 GB\n",
      "Scores for every category: [[2.2446131e-02 2.2295958e-06 9.9788707e-01]]\n",
      "Truth label: [0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = feature_vecs_train[11]\n",
    "print('Feature', df.features[11])\n",
    "a = np.expand_dims(a, axis=-1)\n",
    "print('Scores for every category:', model.predict(a.T))\n",
    "print('Truth label:', train_labels[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True class compartively gets much higher score (scores are close to 0 due to overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter file name for model to save:  my1\n"
     ]
    }
   ],
   "source": [
    "save_model = input('Enter file name for model to save:')\n",
    "model.save(save_model+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'test1.csv' gives an idea of what our input data would look like, and 'out1.csv' would be the corresponding output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
